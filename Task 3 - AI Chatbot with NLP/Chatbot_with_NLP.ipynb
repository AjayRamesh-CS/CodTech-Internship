{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "qA8H0pZuLbw8",
        "outputId": "c766d81f-6b2d-413f-a667-3db90944aa29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAI Chatbot with NLP - Internship Task 3\\nFile: internship_task_3_chatbot.py\\n\\nDescription:\\nA simple, well-commented Python chatbot that uses NLP to answer user queries.\\nThis script includes two modes:\\n  1) Command-line chat loop (default)\\n  2) Optional Flask web endpoint (uncomment to enable)\\n\\nKey features:\\n - Prepares training data (intents + example phrases + responses)\\n - Cleans and lemmatizes input text using NLTK\\n - Vectorizes text using TF-IDF (scikit-learn)\\n - Uses cosine similarity to find the best-matching response\\n - Has a fallback answer when confidence is low\\n - Easy to extend: add intents/responses or switch to spaCy\\n\\nDependencies:\\n - Python 3.8+\\n - nltk\\n - scikit-learn\\n - flask (optional, for web mode)\\n\\nInstall dependencies (recommended):\\n pip install nltk scikit-learn flask\\n\\nYou must also download some NLTK corpora the first time you run:\\n In Python REPL or at top of script (first run):\\n >>> import nltk\\n >>> nltk.download(\\'punkt\\')\\n >>> nltk.download(\\'wordnet\\')\\n >>> nltk.download(\\'omw-1.4\\')\\n\\n\\nHow to run (command line):\\n python internship_task_3_chatbot.py\\n\\nHow to use (web mode):\\n 1) Uncomment the FLASK block at the bottom of this file.\\n 2) Run the script. Then POST /chat with JSON {\"message\": \"Hi\"}\\n\\n\\nAuthor: CodTech Intern\\nDate: 2025\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "AI Chatbot with NLP - Internship Task 3\n",
        "File: internship_task_3_chatbot.py\n",
        "\n",
        "Description:\n",
        "A simple, well-commented Python chatbot that uses NLP to answer user queries.\n",
        "This script includes two modes:\n",
        "  1) Command-line chat loop (default)\n",
        "  2) Optional Flask web endpoint (uncomment to enable)\n",
        "\n",
        "Key features:\n",
        " - Prepares training data (intents + example phrases + responses)\n",
        " - Cleans and lemmatizes input text using NLTK\n",
        " - Vectorizes text using TF-IDF (scikit-learn)\n",
        " - Uses cosine similarity to find the best-matching response\n",
        " - Has a fallback answer when confidence is low\n",
        " - Easy to extend: add intents/responses or switch to spaCy\n",
        "\n",
        "Dependencies:\n",
        " - Python 3.8+\n",
        " - nltk\n",
        " - scikit-learn\n",
        " - flask (optional, for web mode)\n",
        "\n",
        "Install dependencies (recommended):\n",
        " pip install nltk scikit-learn flask\n",
        "\n",
        "You must also download some NLTK corpora the first time you run:\n",
        " In Python REPL or at top of script (first run):\n",
        " >>> import nltk\n",
        " >>> nltk.download('punkt')\n",
        " >>> nltk.download('wordnet')\n",
        " >>> nltk.download('omw-1.4')\n",
        "\n",
        "\n",
        "How to run (command line):\n",
        " python internship_task_3_chatbot.py\n",
        "\n",
        "How to use (web mode):\n",
        " 1) Uncomment the FLASK block at the bottom of this file.\n",
        " 2) Run the script. Then POST /chat with JSON {\"message\": \"Hi\"}\n",
        "\n",
        "\n",
        "Author: CodTech Intern\n",
        "Date: 2025\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Imports\n",
        "# -------------------------\n",
        "import re\n",
        "import random\n",
        "import json\n",
        "from typing import List, Tuple"
      ],
      "metadata": {
        "id": "elvcasF4L_Ap"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP libraries\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "-4z0H9_CMBVm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Machine learning / similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "p-7N3nteMDWp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Flask for a simple web API (uncomment if using web mode)\n",
        "# from flask import Flask, request, jsonify\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Helper functions for NLP preprocessing\n",
        "# -------------------------\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"Lowercase, remove non-alphanumerics and extra spaces.\"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "def lemmatize_text(text: str) -> str:\n",
        "    \"\"\"Tokenize and lemmatize input text, then return re-joined string.\"\"\"\n",
        "    tokens = word_tokenize(text)\n",
        "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return \" \".join(lemmas)\n",
        "\n",
        "\n",
        "def preprocess(text: str) -> str:\n",
        "    \"\"\"Full preprocessing pipeline: clean -> lemmatize.\"\"\"\n",
        "    cleaned = clean_text(text)\n",
        "    lemm = lemmatize_text(cleaned)\n",
        "    return lemm"
      ],
      "metadata": {
        "id": "dsMAIVdvMF8h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Ensure NLTK resources are available\n",
        "# -------------------------\n",
        "# If you haven't downloaded required corpora, uncomment the following lines\n",
        "# and run the script once. Afterwards you can comment them back out.\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u95iv4AMrKA",
        "outputId": "2cc8b2f1-adf0-49fe-bf77-e2752f2345d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Training data (intents)\n",
        "# -------------------------\n",
        "# This is a small example dataset. You can expand it with more intents and examples.\n",
        "intents = [\n",
        "    {\n",
        "        \"tag\": \"greeting\",\n",
        "        \"patterns\": [\n",
        "            \"hi\",\n",
        "            \"hello\",\n",
        "            \"hey\",\n",
        "            \"good morning\",\n",
        "            \"good evening\",\n",
        "            \"hey there\"\n",
        "        ],\n",
        "        \"responses\": [\n",
        "            \"Hello! How can I help you today?\",\n",
        "            \"Hi there — what can I do for you?\",\n",
        "            \"Hey! Ask me anything about this project.\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"tag\": \"goodbye\",\n",
        "        \"patterns\": [\"bye\", \"see you\", \"goodbye\", \"catch you later\"],\n",
        "        \"responses\": [\"Goodbye!\", \"See you later.\", \"Have a nice day!\"]\n",
        "    },\n",
        "    {\n",
        "        \"tag\": \"thanks\",\n",
        "        \"patterns\": [\"thanks\", \"thank you\", \"thx\", \"thanks a lot\"],\n",
        "        \"responses\": [\"You're welcome!\", \"Anytime!\", \"Happy to help.\"]\n",
        "    },\n",
        "    {\n",
        "        \"tag\": \"project_info\",\n",
        "        \"patterns\": [\n",
        "            \"what is this project\",\n",
        "            \"tell me about the project\",\n",
        "            \"what does this do\",\n",
        "            \"explain the internship task\",\n",
        "            \"describe the chatbot\"\n",
        "        ],\n",
        "        \"responses\": [\n",
        "            \"This is a sample NLP chatbot built for the CodTech internship task. It uses NLTK and TF-IDF to match user queries to intents.\",\n",
        "            \"A small chatbot demo using preprocessing (lemmatization) and TF-IDF + cosine similarity to pick responses.\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"tag\": \"how_to_run\",\n",
        "        \"patterns\": [\n",
        "            \"how to run\",\n",
        "            \"how do i run this\",\n",
        "            \"run the script\",\n",
        "            \"execute\"\n",
        "        ],\n",
        "        \"responses\": [\n",
        "            \"Run the script with: python internship_task_3_chatbot.py. Make sure dependencies are installed and NLTK corpora downloaded.\",\n",
        "            \"Install requirements with pip, download NLTK resources (punkt, wordnet) and run the .py file.\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"tag\": \"default_fallback\",\n",
        "        \"patterns\": [\"*\"],\n",
        "        \"responses\": [\n",
        "            \"Sorry, I didn't understand that. Can you phrase it differently?\",\n",
        "            \"I am not sure I follow — try rephrasing or ask something else.\"\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "# -------------------------\n",
        "# Build the knowledge base\n",
        "# -------------------------\n",
        "\n",
        "# We will construct two lists:\n",
        "#  - documents: example phrases (patterns) after preprocessing\n",
        "#  - responses_map: maps each document index to a list of possible responses\n",
        "\n",
        "documents: List[str] = []\n",
        "responses_map: List[List[str]] = []\n",
        "\n",
        "for intent in intents:\n",
        "    tag = intent['tag']\n",
        "    for pattern in intent['patterns']:\n",
        "        processed = preprocess(pattern)\n",
        "        documents.append(processed)\n",
        "        # store the responses for this pattern (could map by tag too)\n",
        "        responses_map.append(intent['responses'])\n",
        "\n",
        "# sanity check\n",
        "if not documents:\n",
        "    raise ValueError(\"No training documents found. Add some patterns to the intents list.\")"
      ],
      "metadata": {
        "id": "6P6i1f2jMIz3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# TF-IDF Vectorizer\n",
        "# -------------------------\n",
        "# Fit the vectorizer on training patterns (documents)\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_docs = vectorizer.fit_transform(documents)\n",
        "\n",
        "# -------------------------\n",
        "# Chatbot logic: respond function\n",
        "# -------------------------\n",
        "\n",
        "def get_response(user_message: str, top_n: int = 1) -> Tuple[str, float]:\n",
        "    \"\"\"Given user input, return best response and similarity score.\n",
        "\n",
        "    Steps:\n",
        "      1) Preprocess user input\n",
        "      2) Vectorize with same TF-IDF vectorizer\n",
        "      3) Compute cosine similarity to training patterns\n",
        "      4) Pick the highest scoring pattern\n",
        "      5) If score is low, return fallback\n",
        "    \"\"\"\n",
        "    if not user_message or not user_message.strip():\n",
        "        return (\"Please say something — I didn't get any input.\", 0.0)\n",
        "\n",
        "    # preprocess + vectorize\n",
        "    processed = preprocess(user_message)\n",
        "    user_vec = vectorizer.transform([processed])\n",
        "\n",
        "    # cosine similarity\n",
        "    sims = cosine_similarity(user_vec, X_docs).flatten()\n",
        "    # find top match\n",
        "    best_idx = sims.argmax()\n",
        "    best_score = float(sims[best_idx])\n",
        "\n",
        "    # threshold for fallback (tweakable)\n",
        "    threshold = 0.35\n",
        "\n",
        "    if best_score < threshold:\n",
        "        # low confidence: return fallback intent responses randomly\n",
        "        # fallback located at tag \"default_fallback\" (last in our intents list)\n",
        "        fallback_intent = next((i for i in intents if i['tag'] == 'default_fallback'), None)\n",
        "        if fallback_intent:\n",
        "            return (random.choice(fallback_intent['responses']), best_score)\n",
        "        else:\n",
        "            return (\"I'm not sure I understand — can you try rephrasing?\", best_score)\n",
        "\n",
        "    # high confidence: pick one response from the matched pattern's response list\n",
        "    candidate_responses = responses_map[best_idx]\n",
        "    chosen = random.choice(candidate_responses)\n",
        "    return (chosen, best_score)"
      ],
      "metadata": {
        "id": "QsvUjjUOMMGQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Command-line chat loop\n",
        "# -------------------------\n",
        "\n",
        "def chat_loop():\n",
        "    print(\"\\n=== CodTech Internship Chatbot (type 'quit' to exit) ===\\n\")\n",
        "    while True:\n",
        "        try:\n",
        "            user = input(\"You: \").strip()\n",
        "        except (KeyboardInterrupt, EOFError):\n",
        "            print(\"\\nExiting. Bye!\")\n",
        "            break\n",
        "\n",
        "        if not user:\n",
        "            print(\"Bot: Please type something.\")\n",
        "            continue\n",
        "\n",
        "        if user.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
        "            print(\"Bot: Goodbye! Good luck with your internship.\")\n",
        "            break\n",
        "\n",
        "        response, score = get_response(user)\n",
        "        # show score for debugging (optional)\n",
        "        print(f\"Bot: {response}  (confidence={score:.2f})\")"
      ],
      "metadata": {
        "id": "6kDco2s7MOY-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Optional Flask Web API\n",
        "# -------------------------\n",
        "# If you prefer a small web endpoint, uncomment and run. Example request:\n",
        "#   POST /chat  JSON body: {\"message\": \"hello\"}\n",
        "#\n",
        "# app = Flask(__name__)\n",
        "#\n",
        "# @app.route('/chat', methods=['POST'])\n",
        "# def chat_api():\n",
        "#     data = request.get_json(force=True)\n",
        "#     message = data.get('message', '')\n",
        "#     response_text, score = get_response(message)\n",
        "#     return jsonify({'response': response_text, 'confidence': score})\n",
        "#\n",
        "# if __name__ == '__main__':\n",
        "#     app.run(host='0.0.0.0', port=5000, debug=True)\n",
        "\n",
        "# -------------------------\n",
        "# Entry point\n",
        "# -------------------------\n",
        "if __name__ == '__main__':\n",
        "    # By default, run the command-line chat loop. To run Flask mode, see above.\n",
        "    chat_loop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjkRDbzFMQTq",
        "outputId": "c23db1a2-bdf0-4a35-cd9c-7d2f937f30ad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== CodTech Internship Chatbot (type 'quit' to exit) ===\n",
            "\n",
            "You: Hi\n",
            "Bot: Hi there — what can I do for you?  (confidence=1.00)\n",
            "You: How is the weather today?\n",
            "Bot: This is a sample NLP chatbot built for the CodTech internship task. It uses NLTK and TF-IDF to match user queries to intents.  (confidence=0.37)\n",
            "You: How are you?\n",
            "Bot: Goodbye!  (confidence=0.42)\n",
            "You: What is my name?\n",
            "Bot: This is a sample NLP chatbot built for the CodTech internship task. It uses NLTK and TF-IDF to match user queries to intents.  (confidence=0.75)\n",
            "You: Thank you\n",
            "Bot: Anytime!  (confidence=1.00)\n",
            "You: Bye\n",
            "Bot: Goodbye! Good luck with your internship.\n"
          ]
        }
      ]
    }
  ]
}